# ğŸ§  Evaluating the Potential of Generative Techniques to Improve Generalization in Federated Learning

This project explores the potential of **generative data augmentation strategies** to improve model generalization in **federated learning**, while preserving data privacy.  

In this context, **synthetic data** is generated locally from real data, without direct sharing between participating sites.

---

## ğŸ¥ Data Used

Experiments were conducted using the **ICU module** of the **MIMIC-IV** database, segmented into five cohorts corresponding to different medical conditions:

- ğŸ«€ Heart Failure  
- ğŸ§½ Chronic Kidney Disease (CKD)  
- ğŸ« Chronic Obstructive Pulmonary Disease (COPD)  
- â¤ï¸ Coronary Artery Disease (CAD)  
- ğŸ”¬ Other conditions (not included in the study)

These cohorts are assumed to be distributed across **four hospitals**, each locally hosting data for one specific condition.

---

## ğŸ“ Project Structure

- `data/` â€“ Simulated or real data (not included)  
- `notebooks/` â€“ Jupyter notebooks for data exploration, modeling, and results  
- `scripts/` â€“ Scripts for data preprocessing, federation, and synthetic data generation  
- `results/` â€“ Figures, model scores, and result summaries

---

## ğŸ¯ Objectives

1. Data preprocessing and cleaning  
2. Training classical models locally  
3. Cross-site evaluation  
4. Implementation of federated learning with:
   - Federated Logistic Regression  
   - Federated XGBoost  
5. Synthetic data generation using **RealTabFormer**  
6. Retraining models on synthetic data  
7. Evaluating generalization performance

---

## ğŸ§ª Models Explored

| Type                       | Model                          |
|----------------------------|--------------------------------|
| Classical                  | Logistic Regression            |
|                            | Random Forest                  |
|                            | XGBoost                        |
|                            | Gradient Boosting              |
| Federated Learning         | Federated Logistic Regression  |
|                            | Federated XGBoost              |
| Generative (Augmentation)  | RealTabFormer                  |

---

## ğŸ” Results

The results compare the performance of:
- **Locally trained models**
- **Federated learning models**
- **Models trained on synthetic data**

Metrics include:
- AU-ROC (Area Under the Receiver Operating Characteristic Curve)  
- AU-PRC (Area Under the Precision-Recall Curve)

---

## ğŸ‘©â€ğŸ’» Author

**Siham Si Hadj Mohand**  
Masterâ€™s in Electrical Engineering Â· Passionate about AI, Data Science, and Embedded Systems
[LinkedIn](www.linkedin.com/in/siham-s) | [Email](siham.sihadj@gmail.com)


---

## ğŸ“š References

- **MIMIC-IV ICU**  
  [https://physionet.org/content/mimiciv/](https://physionet.org/content/mimiciv/)

- **RealTabFormer**  
  [https://github.com/worldbank/REaLTabFormer](https://github.com/worldbank/REaLTabFormer)  
  A. V. Solatorio and O. Dupriez, _â€œREaLTabFormer: Generating realistic relational and tabular data using transformers,â€_  
  *arXiv preprint* [arXiv:2302.02041](https://arxiv.org/abs/2302.02041), 2023.

- **Data Processing Pipeline**  
  M. Gupta, B. M. Gallamoza, N. Cutrona, P. Dhakal, R. Poulain, and R. Beheshti,  
  _â€œAn extensive data processing pipeline for MIMIC-IV,â€_  
  In *Proceedings of the 2nd Machine Learning for Health Symposium*, PMLR, Vol. 193, 2022, pp. 311â€“325.

- **federated XGBoost (Flower)**
  
   Documentation: https://flower.ai/blog/2024-02-14-federated-xgboost-with-flower/
  
   Repository: https://github.com/adap/flower/tree/main/examples/xgboost-quickstart

- **federated Logistic Regression**
  
   Documentation: https://fate.readthedocs.io/en/develop/_build_temp/python/federatedml/linear_model/logistic_regression/README.html
  
   Repository: https://github.com/adap/flower/tree/main/examples/sklearn-logreg-mnist

  

# ğŸ§  Ã‰valuation du potentiel des techniques gÃ©nÃ©ratives pour amÃ©liorer la gÃ©nÃ©ralisation en apprentissage fÃ©dÃ©rÃ©

Ce projet explore le potentiel des **stratÃ©gies dâ€™augmentation de donnÃ©es gÃ©nÃ©ratives** pour amÃ©liorer la gÃ©nÃ©ralisation des modÃ¨les en **apprentissage fÃ©dÃ©rÃ©**, tout en respectant la confidentialitÃ© des donnÃ©es.  

Dans ce contexte, des **donnÃ©es synthÃ©tiques** sont gÃ©nÃ©rÃ©es localement Ã  partir de donnÃ©es rÃ©elles, sans partage direct entre les sites participants.

---

## ğŸ¥ DonnÃ©es utilisÃ©es

Les expÃ©riences ont Ã©tÃ© menÃ©es Ã  partir du module **ICU** de la base de donnÃ©es **MIMIC-IV**, segmentÃ© en cinq cohortes correspondant Ã  diffÃ©rentes pathologies :

- ğŸ«€ Insuffisance cardiaque
- ğŸ§½ Maladie rÃ©nale chronique (CKD)
- ğŸ« Maladie pulmonaire obstructive chronique (COPD)
- â¤ï¸ Maladie coronarienne (CAD)
- ğŸ”¬ Autres maladies (non incluses dans lâ€™Ã©tude)

Ces cohortes sont supposÃ©es rÃ©parties entre **quatre hÃ´pitaux**, chacun hÃ©bergeant localement les donnÃ©es dâ€™une maladie spÃ©cifique.

---

## ğŸ“ Structure du projet

- `data/` : DonnÃ©es simulÃ©es ou rÃ©elles (non incluses)
- `notebooks/` : Notebooks Jupyter pour exploration, modÃ©lisation et rÃ©sultats
- `scripts/` : Scripts pour le traitement, fÃ©dÃ©ration et gÃ©nÃ©ration de donnÃ©es
- `results/` : Graphiques, scores des modÃ¨les

---

## ğŸ¯ Objectifs

1. PrÃ©traitement et nettoyage des donnÃ©es
2. EntraÃ®nement de modÃ¨les classiques localement
3. Ã‰valuation croisÃ©e entre les sites
4. ImplÃ©mentation de lâ€™apprentissage fÃ©dÃ©rÃ© avec :
   - RÃ©gression logistique fÃ©dÃ©rÃ©e
   - XGBoost fÃ©dÃ©rÃ©
5. GÃ©nÃ©ration de donnÃ©es synthÃ©tiques avec **RealTabFormer**
6. RÃ©entraÃ®nement des modÃ¨les sur donnÃ©es synthÃ©tiques
7. Ã‰valuation des performances gÃ©nÃ©ralisÃ©es

---

## ğŸ§ª ModÃ¨les explorÃ©s

| Type                       | ModÃ¨le                       |
|----------------------------|------------------------------|
| Classique                  | RÃ©gression Logistique        |
|                            | Random Forest                |
|                            | XGBoost                      |
|                            | Gradient Boosting            |
| Apprentissage fÃ©dÃ©rÃ©       | RÃ©gression Logistique fÃ©dÃ©rÃ©e |
|                            | XGBoost fÃ©dÃ©rÃ©               |
| GÃ©nÃ©ratif (augmentation)   | RealTabFormer                |

---

## ğŸ” RÃ©sultats

Les rÃ©sultats comparent les performances :
- des modÃ¨les **entraÃ®nÃ©s localement**
- des modÃ¨les **entraÃ®nÃ©s via FL**
- des modÃ¨les **entraÃ®nÃ©s sur donnÃ©es synthÃ©tiques**

Les mÃ©triques incluent :
- AU-ROC
- AU-PRC


---


## ğŸ‘©â€ğŸ’» Auteur

**Siham Si Hadj Mohand**  
MaÃ®trise en gÃ©nie Ã©lectrique Â· PassionnÃ©e par lâ€™IA, la science des donnÃ©es et les systÃ¨mes embarquÃ©s  
[LinkedIn](www.linkedin.com/in/siham-s) | [Email](siham.sihadj@gmail.com)

---

## ğŸ“š RÃ©fÃ©rences

- **MIMIC-IV ICU** : [https://physionet.org/content/mimiciv/](https://physionet.org/content/mimiciv/)
- **RealTabFormer** :
  [https://github.com/worldbank/REaLTabFormer](https://github.com/worldbank/REaLTabFormer)
  
  A. V. Solatorio and O. Dupriez, _â€œREaLTabFormer: Generating realistic relational and tabular data using transformers,â€_  
  *arXiv preprint* [arXiv:2302.02041](https://arxiv.org/abs/2302.02041), 2023.
- **Pipeline de traitement utilisÃ©** :  
  M. Gupta, B. M. Gallamoza, N. Cutrona, P. Dhakal, R. Poulain, and R. Beheshti,  
  _â€œAn extensive data processing pipeline for MIMIC-IV,â€_  
  in *Proceedings of the 2nd Machine Learning for Health Symposium*, PMLR, Vol. 193, 2022, pp. 311â€“325.

- **federated XGBoost (Flower)**
  
   Documentation: https://flower.ai/blog/2024-02-14-federated-xgboost-with-flower/
  
   Repository: https://github.com/adap/flower/tree/main/examples/xgboost-quickstart

- **federated Logistic Regression**
  
   Documentation: https://fate.readthedocs.io/en/develop/_build_temp/python/federatedml/linear_model/logistic_regression/README.html
  
   Repository: https://github.com/adap/flower/tree/main/examples/sklearn-logreg-mnist


